{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cpu\")\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 10\n",
    "DIR = os.getcwd()\n",
    "EPOCHS = 10\n",
    "N_TRAIN_EXAMPLES = BATCHSIZE * 30\n",
    "N_VALID_EXAMPLES = BATCHSIZE * 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def define_model(trial):\n",
    "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    layers = []\n",
    "\n",
    "    in_features = 28 * 28\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
    "        layers.append(nn.Dropout(p))\n",
    "\n",
    "        in_features = out_features\n",
    "    layers.append(nn.Linear(in_features, CLASSES))\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def get_mnist():\n",
    "    # Load FashionMNIST dataset.\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(DIR, train=True, download=True, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCHSIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(DIR, train=False, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCHSIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    # Generate the model.\n",
    "    model = define_model(trial).to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    # Get the FashionMNIST dataset.\n",
    "    train_loader, valid_loader = get_mnist()\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Limiting training data for faster epochs.\n",
    "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "\n",
    "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                # Limiting validation data.\n",
    "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
    "                    break\n",
    "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "                output = model(data)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = correct / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
    "\n",
    "        trial.report(accuracy, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-22 20:08:57,799]\u001B[0m A new study created in memory with name: no-name-25428cb0-90af-4d93-9331-a879552c280a\u001B[0m\n",
      "\u001B[32m[I 2022-11-22 20:08:59,797]\u001B[0m Trial 0 finished with value: 0.26640625 and parameters: {'n_layers': 3, 'n_units_l0': 80, 'dropout_l0': 0.38069646949384367, 'n_units_l1': 100, 'dropout_l1': 0.3826447004683492, 'n_units_l2': 76, 'dropout_l2': 0.42127647501740195, 'optimizer': 'Adam', 'lr': 0.05462003058298224}. Best is trial 0 with value: 0.26640625.\u001B[0m\n",
      "\u001B[32m[I 2022-11-22 20:09:01,696]\u001B[0m Trial 1 finished with value: 0.296875 and parameters: {'n_layers': 3, 'n_units_l0': 78, 'dropout_l0': 0.3595636572712661, 'n_units_l1': 117, 'dropout_l1': 0.20331427057403897, 'n_units_l2': 32, 'dropout_l2': 0.383075740649693, 'optimizer': 'Adam', 'lr': 0.060622086974953054}. Best is trial 1 with value: 0.296875.\u001B[0m\n",
      "\u001B[32m[I 2022-11-22 20:09:03,406]\u001B[0m Trial 2 finished with value: 0.5296875 and parameters: {'n_layers': 2, 'n_units_l0': 7, 'dropout_l0': 0.46555004896590635, 'n_units_l1': 27, 'dropout_l1': 0.39183961142040225, 'optimizer': 'Adam', 'lr': 0.0008928198476932478}. Best is trial 2 with value: 0.5296875.\u001B[0m\n",
      "\u001B[32m[I 2022-11-22 20:09:05,226]\u001B[0m Trial 3 finished with value: 0.73984375 and parameters: {'n_layers': 1, 'n_units_l0': 46, 'dropout_l0': 0.3025580104119761, 'optimizer': 'RMSprop', 'lr': 0.02135130515378098}. Best is trial 3 with value: 0.73984375.\u001B[0m\n",
      "\u001B[32m[I 2022-11-22 20:09:07,022]\u001B[0m Trial 4 finished with value: 0.78828125 and parameters: {'n_layers': 1, 'n_units_l0': 83, 'dropout_l0': 0.30009279257869304, 'optimizer': 'RMSprop', 'lr': 0.013443736804448164}. Best is trial 4 with value: 0.78828125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-22 20:09:08,733]\u001B[0m Trial 5 finished with value: 0.7078125 and parameters: {'n_layers': 2, 'n_units_l0': 13, 'dropout_l0': 0.37537207279227847, 'n_units_l1': 32, 'dropout_l1': 0.4686343636698468, 'optimizer': 'RMSprop', 'lr': 0.0011321686142924412}. Best is trial 4 with value: 0.78828125.\u001B[0m\n",
      "\u001B[32m[I 2022-11-22 20:09:10,779]\u001B[0m Trial 6 finished with value: 0.81015625 and parameters: {'n_layers': 3, 'n_units_l0': 105, 'dropout_l0': 0.3667809264840217, 'n_units_l1': 89, 'dropout_l1': 0.245601066827005, 'n_units_l2': 52, 'dropout_l2': 0.35474929487055146, 'optimizer': 'RMSprop', 'lr': 0.0013503328990983313}. Best is trial 6 with value: 0.81015625.\u001B[0m\n",
      "\u001B[32m[I 2022-11-22 20:09:10,976]\u001B[0m Trial 7 pruned. \u001B[0m\n",
      "\u001B[32m[I 2022-11-22 20:09:12,903]\u001B[0m Trial 8 finished with value: 0.69140625 and parameters: {'n_layers': 2, 'n_units_l0': 91, 'dropout_l0': 0.4693929557185215, 'n_units_l1': 114, 'dropout_l1': 0.278709737139414, 'optimizer': 'Adam', 'lr': 0.019440081931555244}. Best is trial 6 with value: 0.81015625.\u001B[0m\n",
      "\u001B[32m[I 2022-11-22 20:09:13,113]\u001B[0m Trial 9 pruned. \u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  10\n",
      "  Number of pruned trials:  2\n",
      "  Number of complete trials:  8\n",
      "Best trial:\n",
      "  Value:  0.81015625\n",
      "  Params: \n",
      "    n_layers: 3\n",
      "    n_units_l0: 105\n",
      "    dropout_l0: 0.3667809264840217\n",
      "    n_units_l1: 89\n",
      "    dropout_l1: 0.245601066827005\n",
      "    n_units_l2: 52\n",
      "    dropout_l2: 0.35474929487055146\n",
      "    optimizer: RMSprop\n",
      "    lr: 0.0013503328990983313\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=10, timeout=600)\n",
    "\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
