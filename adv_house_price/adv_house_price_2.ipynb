{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, ConcatDataset\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "def define_model(trial):\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    layers = []\n",
    "\n",
    "    in_features = 1\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int('n_units_l{}'.format(i), 4, 128)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        p = trial.suggest_float('droppout_l{}'.format(i), 0.2, 0.5)\n",
    "        layers.append(nn.Dropout(p))\n",
    "\n",
    "        in_features = out_features\n",
    "    layers.append(nn.Linear(in_features, 1))\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "def get_data():\n",
    "\n",
    "    # Basic Pre-Processing\n",
    "    df = pd.read_csv(r'./data/train.csv', index_col='Id')\n",
    "    df = df.dropna(axis=1)\n",
    "    df['MSSubClass'] = df['MSSubClass'].astype('object')\n",
    "    y = df['SalePrice']\n",
    "    X = df.drop('SalePrice', axis=1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "    # Prepare Training DataLoader\n",
    "    train_continuous_features = list(X_train.select_dtypes(include=['int']).columns)\n",
    "    train_categorical_features = list(X_train.select_dtypes(include=['object']).columns)\n",
    "\n",
    "    for col in train_continuous_features:\n",
    "        X_train[col] = X_train[col].astype('int32')\n",
    "    for col in train_categorical_features:\n",
    "        X_train[col] = X_train[col].astype('category')\n",
    "\n",
    "    train_continuous = np.stack([X_train[col].values for col in train_continuous_features], 1)\n",
    "    train_categorical = np.stack([X_train[col].cat.codes.values for col in train_categorical_features], 1)\n",
    "\n",
    "    y = torch.tensor(y_train.values, dtype=torch.float32).reshape(-1, 1)\n",
    "    train_continuous = torch.tensor(train_continuous, dtype=torch.float32)\n",
    "    train_categorical = torch.tensor(train_categorical, dtype=torch.int32)\n",
    "\n",
    "    train_category_sizes = [len(X_train[col].cat.categories) for col in train_categorical_features]\n",
    "    train_embedding_sizes = [(size, min(50, (size+1)//2)) for size in train_category_sizes]\n",
    "    train_self_embeddings = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in train_embedding_sizes])\n",
    "\n",
    "    embeddings = []\n",
    "    for i,e in enumerate(train_self_embeddings):\n",
    "        embeddings.append(e(train_categorical[:,i]))\n",
    "\n",
    "    embedded_categorical = torch.cat(embeddings, 1)\n",
    "    X_train_tensor = torch.cat((train_continuous, embedded_categorical), 1)\n",
    "    train_datset = TensorDataset(X_train_tensor, embedded_categorical)\n",
    "    train_dataloader = DataLoader(train_datset, batch_size=20, shuffle=True)\n",
    "\n",
    "    # Prepare Test DataLoader\n",
    "    test_continuous_features = list(X_test.select_dtypes(include=['int']).columns)\n",
    "    test_categorical_features = list(X_test.select_dtypes(include=['object']).columns)\n",
    "\n",
    "    for col in test_continuous_features:\n",
    "        X_test[col] = X_test[col].astype('int32')\n",
    "    for col in test_categorical_features:\n",
    "        X_test[col] = X_test[col].astype('category')\n",
    "\n",
    "    test_continuous = np.stack([X_test[col].values for col in test_continuous_features], 1)\n",
    "    test_categorical = np.stack([X_test[col].cat.codes.values for col in test_categorical_features], 1)\n",
    "\n",
    "    y = torch.tensor(y_test.values, dtype=torch.float32).reshape(-1, 1)\n",
    "    test_continuous = torch.tensor(test_continuous, dtype=torch.float32)\n",
    "    test_categorical = torch.tensor(test_categorical, dtype=torch.int32)\n",
    "\n",
    "    test_category_sizes = [len(X_test[col].cat.categories) for col in test_categorical_features]\n",
    "    test_embedding_sizes = [(size, min(50, (size+1)//2)) for size in test_category_sizes]\n",
    "    test_self_embeddings = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in test_embedding_sizes])\n",
    "\n",
    "    embeddings = []\n",
    "    for i,e in enumerate(test_self_embeddings):\n",
    "        embeddings.append(e(test_categorical[:,i]))\n",
    "\n",
    "    embedded_categorical = torch.cat(embeddings, 1)\n",
    "    X_test_tensor = torch.cat((test_continuous, embedded_categorical), 1)\n",
    "    test_datset = TensorDataset(X_test_tensor, embedded_categorical)\n",
    "    test_dataloader = DataLoader(test_datset, batch_size=20, shuffle=True)\n",
    "\n",
    "    return train_dataloader, test_dataloader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "train_loader, test_loader = get_data()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "# # Basic Pre-Processing\n",
    "# df = pd.read_csv(r'./data/train.csv', index_col='Id')\n",
    "# df = df.dropna(axis=1)\n",
    "# df['MSSubClass'] = df['MSSubClass'].astype('object')\n",
    "# y = df['SalePrice']\n",
    "# X = df.drop('SalePrice', axis=1)\n",
    "#\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "#\n",
    "# # Prepare Training DataLoader\n",
    "# train_continuous_features = list(X_train.select_dtypes(include=['int']).columns)\n",
    "# train_categorical_features = list(X_train.select_dtypes(include=['object']).columns)\n",
    "#\n",
    "# for col in train_continuous_features:\n",
    "#     X_train[col] = X_train[col].astype('int32')\n",
    "# for col in train_categorical_features:\n",
    "#     X_train[col] = X_train[col].astype('category')\n",
    "#\n",
    "# train_continuous = np.stack([X_train[col].values for col in train_continuous_features], 1)\n",
    "# train_categorical = np.stack([X_train[col].cat.codes.values for col in train_categorical_features], 1)\n",
    "#\n",
    "# y = torch.tensor(y_train.values, dtype=torch.float32).reshape(-1, 1)\n",
    "# train_continuous = torch.tensor(train_continuous, dtype=torch.float32)\n",
    "# train_categorical = torch.tensor(train_categorical, dtype=torch.int32)\n",
    "#\n",
    "# train_category_sizes = [len(X_train[col].cat.categories) for col in train_categorical_features]\n",
    "# train_embedding_sizes = [(size, min(50, (size+1)//2)) for size in train_category_sizes]\n",
    "# train_self_embeddings = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in train_embedding_sizes])\n",
    "#\n",
    "# embeddings = []\n",
    "# for i,e in enumerate(train_self_embeddings):\n",
    "#     embeddings.append(e(train_categorical[:,i]))\n",
    "#\n",
    "# embedded_categorical = torch.cat(embeddings, 1)\n",
    "# X_train_tensor = torch.cat((train_continuous, embedded_categorical), 1)\n",
    "# train_datset = TensorDataset(X_train_tensor, embedded_categorical)\n",
    "# train_dataloader = DataLoader(train_datset, batch_size=20, shuffle=True)\n",
    "#\n",
    "# # Prepare Test DataLoader\n",
    "# test_continuous_features = list(X_test.select_dtypes(include=['int']).columns)\n",
    "# test_categorical_features = list(X_test.select_dtypes(include=['object']).columns)\n",
    "#\n",
    "# for col in test_continuous_features:\n",
    "#     X_test[col] = X_test[col].astype('int32')\n",
    "# for col in test_categorical_features:\n",
    "#     X_test[col] = X_test[col].astype('category')\n",
    "#\n",
    "# test_continuous = np.stack([X_test[col].values for col in test_continuous_features], 1)\n",
    "# test_categorical = np.stack([X_test[col].cat.codes.values for col in test_categorical_features], 1)\n",
    "#\n",
    "# y = torch.tensor(y_test.values, dtype=torch.float32).reshape(-1, 1)\n",
    "# test_continuous = torch.tensor(test_continuous, dtype=torch.float32)\n",
    "# test_categorical = torch.tensor(test_categorical, dtype=torch.int32)\n",
    "#\n",
    "# test_category_sizes = [len(X_test[col].cat.categories) for col in test_categorical_features]\n",
    "# test_embedding_sizes = [(size, min(50, (size+1)//2)) for size in test_category_sizes]\n",
    "# test_self_embeddings = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in test_embedding_sizes])\n",
    "#\n",
    "# embeddings = []\n",
    "# for i,e in enumerate(test_self_embeddings):\n",
    "#     embeddings.append(e(test_categorical[:,i]))\n",
    "#\n",
    "# embedded_categorical = torch.cat(embeddings, 1)\n",
    "# X_test_tensor = torch.cat((test_continuous, embedded_categorical), 1)\n",
    "# test_datset = TensorDataset(X_test_tensor, embedded_categorical)\n",
    "# test_dataloader = DataLoader(test_datset, batch_size=20, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
